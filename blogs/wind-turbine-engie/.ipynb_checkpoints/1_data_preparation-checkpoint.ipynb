{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "historic-bangkok",
   "metadata": {},
   "source": [
    "# Data prepartion\n",
    "---\n",
    "In this notebook, we're going to:\n",
    "1. fetch fetch open source data from https://opendata-renewables.engie.com/ and \n",
    "2. preprocess it for for further analysis in the subsequent notebooks.\n",
    "\n",
    "Open source data is made availabble by Engie group and is distributed under Open License version 2.0 published by Etalab.\n",
    "\n",
    "\n",
    "## Step 1: Fetch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "severe-personality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare variables for web scraping the data\n",
    "URL = 'https://opendata-renewables.engie.com'\n",
    "LOCAL_DATA = 'data'\n",
    "URL_DIR = f'{LOCAL_DATA}/web_scrape'\n",
    "\n",
    "# Set target locations in S3\n",
    "BUCKET = 'l4e-demo'\n",
    "PREFIX = 'wind-turbine/training_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "central-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "champion-pride",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-08 04:28:59--  https://opendata-renewables.engie.com/\n",
      "Resolving opendata-renewables.engie.com (opendata-renewables.engie.com)... 94.143.221.195\n",
      "Connecting to opendata-renewables.engie.com (opendata-renewables.engie.com)|94.143.221.195|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/html]\n",
      "Saving to: ‘data/web_scrape/index.html’\n",
      "\n",
      "data/web_scrape/ind     [ <=>                ]  24.69K  --.-KB/s    in 0.09s   \n",
      "\n",
      "2021-04-08 04:28:59 (284 KB/s) - ‘data/web_scrape/index.html’ saved [25280]\n",
      "\n",
      "--2021-04-08 04:28:59--  https://opendata-renewables.engie.com/media/datasets/6eeb7f50-97f7-4ab2-8d36-c6d9f9491d84.zip\n",
      "Resolving opendata-renewables.engie.com (opendata-renewables.engie.com)... 94.143.221.195\n",
      "Connecting to opendata-renewables.engie.com (opendata-renewables.engie.com)|94.143.221.195|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 456 [application/zip]\n",
      "Saving to: ‘data/web_scrape/raw_zip/6eeb7f50-97f7-4ab2-8d36-c6d9f9491d84.zip’\n",
      "\n",
      "6eeb7f50-97f7-4ab2- 100%[===================>]     456  --.-KB/s    in 0s      \n",
      "\n",
      "2021-04-08 04:29:00 (72.3 MB/s) - ‘data/web_scrape/raw_zip/6eeb7f50-97f7-4ab2-8d36-c6d9f9491d84.zip’ saved [456/456]\n",
      "\n",
      "--2021-04-08 04:29:00--  https://opendata-renewables.engie.com/media/datasets/01c55756-5cd6-4f60-9f63-2d771bb25a1a.zip\n",
      "Reusing existing connection to opendata-renewables.engie.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 61916781 (59M) [application/zip]\n",
      "Saving to: ‘data/web_scrape/raw_zip/01c55756-5cd6-4f60-9f63-2d771bb25a1a.zip’\n",
      "\n",
      "01c55756-5cd6-4f60- 100%[===================>]  59.05M  10.0MB/s    in 7.1s    \n",
      "\n",
      "2021-04-08 04:29:07 (8.37 MB/s) - ‘data/web_scrape/raw_zip/01c55756-5cd6-4f60-9f63-2d771bb25a1a.zip’ saved [61916781/61916781]\n",
      "\n",
      "--2021-04-08 04:29:07--  https://opendata-renewables.engie.com/media/datasets/d543716b-368d-4c53-8fb1-55addbe8d3ad.zip\n",
      "Reusing existing connection to opendata-renewables.engie.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 267454163 (255M) [application/zip]\n",
      "Saving to: ‘data/web_scrape/raw_zip/d543716b-368d-4c53-8fb1-55addbe8d3ad.zip’\n",
      "\n",
      "d543716b-368d-4c53- 100%[===================>] 255.06M  3.40MB/s    in 47s     \n",
      "\n",
      "2021-04-08 04:29:54 (5.37 MB/s) - ‘data/web_scrape/raw_zip/d543716b-368d-4c53-8fb1-55addbe8d3ad.zip’ saved [267454163/267454163]\n",
      "\n",
      "--2021-04-08 04:29:54--  https://opendata-renewables.engie.com/media/datasets/39490fd2-04a2-4622-9042-ce4dd34c2a58.zip\n",
      "Reusing existing connection to opendata-renewables.engie.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 705 [application/zip]\n",
      "Saving to: ‘data/web_scrape/raw_zip/39490fd2-04a2-4622-9042-ce4dd34c2a58.zip’\n",
      "\n",
      "39490fd2-04a2-4622- 100%[===================>]     705  --.-KB/s    in 0s      \n",
      "\n",
      "2021-04-08 04:29:55 (141 MB/s) - ‘data/web_scrape/raw_zip/39490fd2-04a2-4622-9042-ce4dd34c2a58.zip’ saved [705/705]\n",
      "\n",
      "FINISHED --2021-04-08 04:29:55--\n",
      "Total wall clock time: 55s\n",
      "Downloaded: 4 files, 314M in 55s (5.76 MB/s)\n"
     ]
    }
   ],
   "source": [
    "# create a wroking directory for web scraping operations\n",
    "!mkdir $LOCAL_DATA\n",
    "!mkdir $URL_DIR\n",
    "\n",
    "# download index.html\n",
    "!wget --output-document=$URL_DIR/index.html $URL\n",
    "\n",
    "# scrape with BS\n",
    "with open(f'{URL_DIR}/index.html') as fp:\n",
    "    soup = BeautifulSoup(fp, \"html.parser\")\n",
    "\n",
    "# get url paths to the raw zipped files\n",
    "data_urls = [URL + x['href'].\\\n",
    "        replace('explore','media'). \\\n",
    "        replace('dataset','datasets'). \\\n",
    "        replace('/information','.zip') \\\n",
    "        for x in list(set([x for x in soup.find_all('a', href=True) if 'dataset' in x['href']]))]\n",
    "\n",
    "# store url paths as a text\n",
    "with open(f'{URL_DIR}/url_list.txt', 'w') as f:\n",
    "    for item in data_urls:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n",
    "# download raw zipped data files\n",
    "!wget --input $URL_DIR/url_list.txt --directory-prefix=$URL_DIR/raw_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "weekly-architecture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01c55756-5cd6-4f60-9f63-2d771bb25a1a.zip',\n",
       " '39490fd2-04a2-4622-9042-ce4dd34c2a58.zip',\n",
       " '6eeb7f50-97f7-4ab2-8d36-c6d9f9491d84.zip',\n",
       " 'd543716b-368d-4c53-8fb1-55addbe8d3ad.zip']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_files = !ls $URL_DIR/raw_zip\n",
    "zip_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "applied-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip files\n",
    "for zip_file_ in zip_files:\n",
    "    with zipfile.ZipFile(f'{URL_DIR}/raw_zip/{zip_file_}', 'r') as zip_ref:\n",
    "        zip_ref.extractall(f'{URL_DIR}/raw_unzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "living-uganda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_description.csv',\n",
       " 'la-haute-borne-data-2013-2016.csv',\n",
       " 'la-haute-borne-data-2017-2020.csv',\n",
       " 'static-information.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print unzipped files names\n",
    "unzipped_files = !ls $URL_DIR/raw_unzip\n",
    "unzipped_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-shade",
   "metadata": {},
   "source": [
    "## Step 2: Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acoustic-skill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['la-haute-borne-data-2013-2016.csv', 'la-haute-borne-data-2017-2020.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = [x for x in unzipped_files if '-data-' in x]\n",
    "data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ethical-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of turbines in the data: ['R80711' 'R80736' 'R80790' 'R80721']\n"
     ]
    }
   ],
   "source": [
    "# read\n",
    "df_1 = pd.read_csv(f'{URL_DIR}/raw_unzip/{data_files[0]}', delimiter=';')\n",
    "df_2 = pd.read_csv(f'{URL_DIR}/raw_unzip/{data_files[1]}', delimiter=';')\n",
    "df_c = pd.concat([df_1 ,df_2], axis=0)\n",
    "\n",
    "turbines = df_c['Wind_turbine_name'].unique()\n",
    "print(f'List of turbines in the data: {turbines}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "tracked-project",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/lookout-for-equipment-demo/blogs/wind-turbine-engie/utils.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Timestamp'] = pd.to_datetime(df['Date_time'], infer_datetime_format=True, utc=True)\n",
      "/home/ec2-user/SageMaker/lookout-for-equipment-demo/blogs/wind-turbine-engie/utils.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop_duplicates(subset=['Timestamp'], keep='first', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "for turbine in turbines:\n",
    "    df_raw = df_c.loc[df_c['Wind_turbine_name'] == turbine,:]\n",
    "    df_clean = clean_up_data(df_raw)\n",
    "    df_description = pd.read_csv(f'{URL_DIR}/raw_unzip/data_description.csv', delimiter=';')\n",
    "    df_ord = order_columns(df_clean, df_description)\n",
    "    df_ord = df_ord.loc[:,~df_ord.columns.duplicated()]\n",
    "    df_ord.to_csv(f's3://{BUCKET}/{PREFIX}/{turbine}/telemetry.csv')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "formal-copyright",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up\n",
    "!rm -rf data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
