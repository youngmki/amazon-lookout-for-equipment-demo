{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Amazon Lookout for Equipment** - 익명화한 익스펜더 데이터셋에 대한 데모\n",
    "*파트 5: 정기적인 추론 호출 스케줄링*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = '<YOUR_BUCKET_NAME_HERE>'\n",
    "PREFIX = 'data/scheduled_inference'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 초기화\n",
    "---\n",
    "이 노트북에서는 데이터 폴더에 추론 디렉토리를 추가하게끔 저장소 구조를 갱신합니다.\n",
    "```\n",
    "/lookout-equipment-demo\n",
    "|\n",
    "+-- data/\n",
    "|   |\n",
    "|   +-- inference/\n",
    "|   |   |\n",
    "|   |   |-- input/\n",
    "|   |   |\n",
    "|   |   \\-- output/\n",
    "|   |\n",
    "|   +-- labelled-data/\n",
    "|   |   \\-- labels.csv\n",
    "|   |\n",
    "|   \\-- training-data/\n",
    "|       \\-- expander/\n",
    "|           |-- subsystem-01\n",
    "|           |   \\-- subsystem-01.csv\n",
    "|           |\n",
    "|           |-- subsystem-02\n",
    "|           |   \\-- subsystem-02.csv\n",
    "|           |\n",
    "|           |-- ...\n",
    "|           |\n",
    "|           \\-- subsystem-24\n",
    "|               \\-- subsystem-24.csv\n",
    "|\n",
    "+-- dataset/\n",
    "|   |-- labels.csv\n",
    "|   |-- tags_description.csv\n",
    "|   |-- timeranges.txt\n",
    "|   \\-- timeseries.zip\n",
    "|\n",
    "+-- notebooks/\n",
    "|   |-- 1_data_preparation.ipynb\n",
    "|   |-- 2_dataset_creation.ipynb\n",
    "|   |-- 3_model_training.ipynb\n",
    "|   |-- 4_model_evaluation.ipynb\n",
    "|   \\-- 5_inference_scheduling.ipynb        <<< 본 노트북 <<<\n",
    "|\n",
    "+-- utils/\n",
    "    |-- lookout_equipment_utils.py\n",
    "    \\-- lookoutequipment.json\n",
    "```\n",
    "\n",
    "### 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "pip -q install --upgrade pip\n",
    "pip -q install --upgrade awscli boto3 sagemaker\n",
    "aws configure add-model --service-model file://../utils/lookoutequipment.json --service-name lookoutequipment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import sagemaker\n",
    "import s3fs\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import warnings\n",
    "\n",
    "# Lookout for Equipment API 호출 관리를 위한 Helper 함수\n",
    "sys.path.append('../utils')\n",
    "import lookout_equipment_utils as lookout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA       = os.path.join('..', 'data')\n",
    "RAW_DATA   = os.path.join('..', 'dataset')\n",
    "INFER_DATA = os.path.join(DATA, 'inference')\n",
    "\n",
    "\n",
    "os.makedirs(os.path.join(INFER_DATA, 'input'), exist_ok=True)\n",
    "os.makedirs(os.path.join(INFER_DATA, 'output'), exist_ok=True)\n",
    "\n",
    "ROLE_ARN = sagemaker.get_execution_role()\n",
    "REGION_NAME = boto3.session.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추론 스케줄러 생성하기\n",
    "---\n",
    "콘솔의 모델 세부 정보 부분으로 이동하면 추론 스케줄이 아직 없음을 확인할 수 있습니다.\n",
    "\n",
    "![Schedule Starting point](../assets/schedule_start.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 스케줄러 설정\n",
    "새로운 추론 스케줄을 만들어 보겠습니다. 파라미터 일부는 필수 입력이지만 파라미터 다수는 유연하게 추가 설정할 수 있습니다.\n",
    "\n",
    "#### 파라미터\n",
    "\n",
    "* 추론을 위해 데이터를 업로드할 빈도로 `DATA_UPLOAD_FREQUENCY`를 설정합니다. 허용되는 값은`PT5M`,`PT10M`,`PT15M`,`PT30M`과`PT1H`입니다.\n",
    "  * 이것은 추론 스케줄러가 실행되는 빈도와 데이터가 소스 버킷에 업로드되는 빈도입니다.\n",
    "  * **참고** : ***업로드 빈도는 훈련 때 선택한 샘플링 비율과 호환되어야합니다.*** *예를 들어 모델을 30분 간격의 리샘플링으로 훈련시킨 경우 5분은 가능하지 않습니다. 추론 시 파라미터로 PT30M 또는 PT1H를 선택해야합니다.*\n",
    "* 추론 데이터의 S3 버킷으로 `INFERENCE_DATA_SOURCE_BUCKET`를 설정합니다.\n",
    "* 추론 데이터의 S3 접두사로 `INFERENCE_DATA_SOURCE_PREFIX`를 설정합니다.\n",
    "* 추론 결과를 원하는 S3 버킷으로 `INFERENCE_DATA_OUTPUT_BUCKET`를 설정합니다.\n",
    "* 추론 결과를 원하는 S3 접두사로 `INFERENCE_DATA_OUTPUT_PREFIX`를 설정합니다.\n",
    "* 추론할 데이터를 **읽고** 추론 출력을 **쓸** 때 사용할 역할로 `ROLE_ARN_FOR_INFERENCE`를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성하려는 추론 스케줄러의 이름\n",
    "INFERENCE_SCHEDULER_NAME = 'lookout-demo-model-v1-scheduler'\n",
    "\n",
    "# 본 추론 스케줄러를 생성할 모델의 이름\n",
    "MODEL_NAME_FOR_CREATING_INFERENCE_SCHEDULER = 'lookout-demo-model-v1'\n",
    "\n",
    "# 필수 입력 파라미터\n",
    "INFERENCE_DATA_SOURCE_BUCKET = BUCKET\n",
    "INFERENCE_DATA_SOURCE_PREFIX = f'{PREFIX}/input/'\n",
    "INFERENCE_DATA_OUTPUT_BUCKET = BUCKET\n",
    "INFERENCE_DATA_OUTPUT_PREFIX = f'{PREFIX}/output/'\n",
    "ROLE_ARN_FOR_INFERENCE = ROLE_ARN\n",
    "DATA_UPLOAD_FREQUENCY = 'PT5M' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 생략 가능한 파라미터\n",
    "\n",
    "* 데이터 업로드하는데 지연이 예상되는 시간(분)으로 `DATA_DELAY_OFFSET_IN_MINUTES`를 설정합니다. 즉, 데이터 업로드하는 시간에 대한 버퍼입니다.\n",
    "* ``INPUT_TIMEZONE_OFFSET``을 설정합니다. 허용되는 값은 +00:00, +00:30, -01:00, ... +11:30, +12:00, -00:00, -00:30, -01:00, ... -11:30, -12:00입니다.\n",
    "* `TIMESTAMP_FORMAT`을 설정합니다. 허용되는 값은 `EPOCH`, `yyyy-MM-dd-HH-mm-ss` 또는 `yyyyMMddHHmmss`입니다. 이것은 입력 데이터 파일 명에 접미사로 붙는 타임스탬프 형식입니다. 이것은 Lookout Equipment에서 추론을 실행할 파일을 파악하는 데 사용됩니다 (그러므로 스케줄러가 실행할 파일을 찾게 하기 위해 이전 파일을 제거할 필요가 없음).\n",
    "* `COMPONENT_TIMESTAMP_DELIMITER`를 설정합니다. 허용되는 값은 `-`, `_` 또는 ` `입니다. 입력 파일 명의 타임스탬프에서 구성 요소를 분리할 때 사용하는 구분자입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DELAY_OFFSET_IN_MINUTES = None\n",
    "INPUT_TIMEZONE_OFFSET = '+00:00'\n",
    "COMPONENT_TIMESTAMP_DELIMITER = '_'\n",
    "TIMESTAMP_FORMAT = 'yyyyMMddHHmmss'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추론 스케줄러 생성하기\n",
    "CreateInferenceScheduler API는 스케줄러를 생성**하고** 구동시킵니다. 즉, 즉각적으로 비용이 발생하기 시작합니다. 그러나 기존 스케줄러를 원하는대로 중지하거나 재구동시킬 수 있습니다 (이 노트북의 마지막 부분 참조)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = lookout.LookoutEquipmentScheduler(\n",
    "    scheduler_name=INFERENCE_SCHEDULER_NAME,\n",
    "    model_name=MODEL_NAME_FOR_CREATING_INFERENCE_SCHEDULER,\n",
    "    region_name=REGION_NAME\n",
    ")\n",
    "\n",
    "scheduler_params = {\n",
    "    'input_bucket': INFERENCE_DATA_SOURCE_BUCKET,\n",
    "    'input_prefix': INFERENCE_DATA_SOURCE_PREFIX,\n",
    "    'output_bucket': INFERENCE_DATA_OUTPUT_BUCKET,\n",
    "    'output_prefix': INFERENCE_DATA_OUTPUT_PREFIX,\n",
    "    'role_arn': ROLE_ARN_FOR_INFERENCE,\n",
    "    'upload_frequency': DATA_UPLOAD_FREQUENCY,\n",
    "    'delay_offset': DATA_DELAY_OFFSET_IN_MINUTES,\n",
    "    'timezone_offset': INPUT_TIMEZONE_OFFSET,\n",
    "    'component_delimiter': COMPONENT_TIMESTAMP_DELIMITER,\n",
    "    'timestamp_format': TIMESTAMP_FORMAT\n",
    "}\n",
    "\n",
    "scheduler.set_parameters(**scheduler_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추론 데이터 준비하기\n",
    "---\n",
    "스케줄러가 모니터링할 S3 입력 위치에 몇 가지 데이터를 준비하고 전송하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal-001</th>\n",
       "      <th>signal-002</th>\n",
       "      <th>signal-003</th>\n",
       "      <th>signal-004</th>\n",
       "      <th>signal-005</th>\n",
       "      <th>signal-006</th>\n",
       "      <th>signal-007</th>\n",
       "      <th>signal-008</th>\n",
       "      <th>signal-009</th>\n",
       "      <th>signal-010</th>\n",
       "      <th>...</th>\n",
       "      <th>signal-113</th>\n",
       "      <th>signal-114</th>\n",
       "      <th>signal-115</th>\n",
       "      <th>signal-116</th>\n",
       "      <th>signal-117</th>\n",
       "      <th>signal-118</th>\n",
       "      <th>signal-119</th>\n",
       "      <th>signal-120</th>\n",
       "      <th>signal-121</th>\n",
       "      <th>signal-122</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00</th>\n",
       "      <td>0.392371</td>\n",
       "      <td>0.545005</td>\n",
       "      <td>0.296774</td>\n",
       "      <td>0.413289</td>\n",
       "      <td>0.170744</td>\n",
       "      <td>0.482980</td>\n",
       "      <td>0.222063</td>\n",
       "      <td>0.268691</td>\n",
       "      <td>0.749860</td>\n",
       "      <td>0.475116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.653465</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.810345</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.810345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:01:00</th>\n",
       "      <td>0.389415</td>\n",
       "      <td>0.569155</td>\n",
       "      <td>0.290645</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>0.142368</td>\n",
       "      <td>0.532297</td>\n",
       "      <td>0.222063</td>\n",
       "      <td>0.290804</td>\n",
       "      <td>0.776781</td>\n",
       "      <td>0.486884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.653465</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.810345</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.810345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:02:00</th>\n",
       "      <td>0.378179</td>\n",
       "      <td>0.547750</td>\n",
       "      <td>0.290645</td>\n",
       "      <td>0.406456</td>\n",
       "      <td>0.160959</td>\n",
       "      <td>0.470115</td>\n",
       "      <td>0.235673</td>\n",
       "      <td>0.277115</td>\n",
       "      <td>0.782389</td>\n",
       "      <td>0.472665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.653465</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.810345</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.810345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:03:00</th>\n",
       "      <td>0.381135</td>\n",
       "      <td>0.547750</td>\n",
       "      <td>0.284516</td>\n",
       "      <td>0.401744</td>\n",
       "      <td>0.170744</td>\n",
       "      <td>0.498794</td>\n",
       "      <td>0.249284</td>\n",
       "      <td>0.270446</td>\n",
       "      <td>0.771733</td>\n",
       "      <td>0.484432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.653465</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.810345</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.810345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:04:00</th>\n",
       "      <td>0.381135</td>\n",
       "      <td>0.553238</td>\n",
       "      <td>0.284516</td>\n",
       "      <td>0.406456</td>\n",
       "      <td>0.142368</td>\n",
       "      <td>0.493433</td>\n",
       "      <td>0.194842</td>\n",
       "      <td>0.272025</td>\n",
       "      <td>0.749860</td>\n",
       "      <td>0.484432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.653465</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.810345</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.810345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     signal-001  signal-002  signal-003  signal-004  \\\n",
       "Timestamp                                                             \n",
       "2015-01-01 00:00:00    0.392371    0.545005    0.296774    0.413289   \n",
       "2015-01-01 00:01:00    0.389415    0.569155    0.290645    0.415646   \n",
       "2015-01-01 00:02:00    0.378179    0.547750    0.290645    0.406456   \n",
       "2015-01-01 00:03:00    0.381135    0.547750    0.284516    0.401744   \n",
       "2015-01-01 00:04:00    0.381135    0.553238    0.284516    0.406456   \n",
       "\n",
       "                     signal-005  signal-006  signal-007  signal-008  \\\n",
       "Timestamp                                                             \n",
       "2015-01-01 00:00:00    0.170744    0.482980    0.222063    0.268691   \n",
       "2015-01-01 00:01:00    0.142368    0.532297    0.222063    0.290804   \n",
       "2015-01-01 00:02:00    0.160959    0.470115    0.235673    0.277115   \n",
       "2015-01-01 00:03:00    0.170744    0.498794    0.249284    0.270446   \n",
       "2015-01-01 00:04:00    0.142368    0.493433    0.194842    0.272025   \n",
       "\n",
       "                     signal-009  signal-010  ...  signal-113  signal-114  \\\n",
       "Timestamp                                    ...                           \n",
       "2015-01-01 00:00:00    0.749860    0.475116  ...    0.939024    0.830769   \n",
       "2015-01-01 00:01:00    0.776781    0.486884  ...    0.939024    0.830769   \n",
       "2015-01-01 00:02:00    0.782389    0.472665  ...    0.939024    0.830769   \n",
       "2015-01-01 00:03:00    0.771733    0.484432  ...    0.939024    0.830769   \n",
       "2015-01-01 00:04:00    0.749860    0.484432  ...    0.939024    0.830769   \n",
       "\n",
       "                     signal-115  signal-116  signal-117  signal-118  \\\n",
       "Timestamp                                                             \n",
       "2015-01-01 00:00:00    0.811321    0.653465    0.789474    0.810345   \n",
       "2015-01-01 00:01:00    0.811321    0.653465    0.789474    0.810345   \n",
       "2015-01-01 00:02:00    0.811321    0.653465    0.789474    0.810345   \n",
       "2015-01-01 00:03:00    0.811321    0.653465    0.789474    0.810345   \n",
       "2015-01-01 00:04:00    0.811321    0.653465    0.789474    0.810345   \n",
       "\n",
       "                     signal-119  signal-120  signal-121  signal-122  \n",
       "Timestamp                                                            \n",
       "2015-01-01 00:00:00    0.803571    0.787879    0.764706    0.810345  \n",
       "2015-01-01 00:01:00    0.803571    0.787879    0.779412    0.810345  \n",
       "2015-01-01 00:02:00    0.803571    0.787879    0.764706    0.810345  \n",
       "2015-01-01 00:03:00    0.803571    0.787879    0.764706    0.810345  \n",
       "2015-01-01 00:04:00    0.803571    0.787879    0.764706    0.810345  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원본 신호 전체를 불러오겠습니다.\n",
    "all_tags_fname = os.path.join(DATA, 'training-data', 'expander.parquet')\n",
    "table = pq.read_table(all_tags_fname)\n",
    "all_tags_df = table.to_pandas()\n",
    "del table\n",
    "all_tags_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "태그 설명을 불러옵시다. 본 데이터셋에는 다음 내용을 포함하는 태그 설명 파일이 존재합니다.\n",
    "\n",
    "* `Tag`: 이력 관리 시스템에 고객이 기록한 태그 명 (예컨대 [Honeywell 프로세스 이력 데이터베이스](https://www.honeywellprocess.com/en-US/explore/products/advanced-applications/uniformance/Pages/uniformance-phd.aspx))\n",
    "* `UOM`: 기록한 신호의 측정 단위\n",
    "* `Subsystem`: 해당 센서가 연결된 자산 부속의 ID\n",
    "\n",
    "여기에서 구성 요소 (즉, 하위 시스템 열)의 List를 수집할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>UOM</th>\n",
       "      <th>Subsystem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>signal-001</td>\n",
       "      <td>micra pp</td>\n",
       "      <td>subsystem-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>signal-002</td>\n",
       "      <td>micra pp</td>\n",
       "      <td>subsystem-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>signal-003</td>\n",
       "      <td>micra pp</td>\n",
       "      <td>subsystem-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>signal-004</td>\n",
       "      <td>micra pp</td>\n",
       "      <td>subsystem-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>signal-005</td>\n",
       "      <td>micra pp</td>\n",
       "      <td>subsystem-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Tag       UOM     Subsystem\n",
       "0  signal-001  micra pp  subsystem-05\n",
       "1  signal-002  micra pp  subsystem-05\n",
       "2  signal-003  micra pp  subsystem-05\n",
       "3  signal-004  micra pp  subsystem-05\n",
       "4  signal-005  micra pp  subsystem-08"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_description_fname = os.path.join(RAW_DATA, 'tags_description.csv')\n",
    "tags_description_df = pd.read_csv(tags_description_fname)\n",
    "components = tags_description_df['Subsystem'].unique()\n",
    "tags_description_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "샘플 추론 데이터셋을 구성하기 위해 원본 시계열 검증 기간에서 마지막 몇 분을 추출합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from 2015-11-30 23:45:00 to 2015-11-30 23:49:00:\n",
      "Extracting data from 2015-11-30 23:50:00 to 2015-11-30 23:54:00:\n",
      "Extracting data from 2015-11-30 23:55:00 to 2015-11-30 23:59:00:\n",
      "===== Polling Inference Scheduler Status =====\n",
      "\n",
      "Scheduler Status: PENDING\n",
      "Scheduler Status: RUNNING\n",
      "\n",
      "===== End of Polling Inference Scheduler Status =====\n"
     ]
    }
   ],
   "source": [
    "# 추출하려는 시퀀스 개수\n",
    "num_sequences = 3\n",
    "\n",
    "# 스케줄링 빈도 (분): 이 값은 **반드시**\n",
    "# 모델 학습에 사용한 리샘플링 비율에 맞춰 설정해야 합니다. \n",
    "frequency = 5\n",
    "\n",
    "# 각 시퀀스를 반복합니다.\n",
    "start = all_tags_df.index.max() + datetime.timedelta(minutes=-frequency * (num_sequences) + 1)\n",
    "for i in range(num_sequences):\n",
    "    end = start + datetime.timedelta(minutes=+frequency - 1)\n",
    "    \n",
    "    # 이전 5분 단위로 시간을 반올림합니다.\n",
    "    tm = datetime.datetime.now()\n",
    "    tm = tm - datetime.timedelta(\n",
    "        minutes=tm.minute % frequency,\n",
    "        seconds=tm.second,\n",
    "        microseconds=tm.microsecond\n",
    "    )\n",
    "    tm = tm + datetime.timedelta(minutes=+frequency * (i))\n",
    "    tm = tm - datetime.timedelta(hours=9) # KST에 따른 조정\n",
    "    current_timestamp = (tm).strftime(format='%Y%m%d%H%M%S')\n",
    "\n",
    "    # 각 시퀀스마다 구성 요소 전체를 반복합니다. \n",
    "    print(f'Extracting data from {start} to {end}:')\n",
    "    new_index = None\n",
    "    for component in components:\n",
    "        # 해당 구성 요소와 특정 시간 범위에 대해 Dataframe을 추출합니다.\n",
    "        signals = list(tags_description_df.loc[(tags_description_df['Subsystem'] == component), 'Tag'])\n",
    "        signals_df = all_tags_df.loc[start:end, signals]\n",
    "        \n",
    "        # 스케줄러가 추론을 실행할 시간에 맞게끔\n",
    "        # 인덱스를 재설정해야 합니다. \n",
    "        if new_index is None:\n",
    "            new_index = pd.date_range(\n",
    "                start=tm,\n",
    "                periods=signals_df.shape[0], \n",
    "                freq='1min'\n",
    "            )\n",
    "        signals_df.index = new_index\n",
    "        signals_df.index.name = 'Timestamp'\n",
    "        signals_df = signals_df.reset_index()\n",
    "        signals_df['Timestamp'] = signals_df['Timestamp'].dt.strftime('%Y-%m-%dT%H:%M:%S.%f')\n",
    "\n",
    "        # 해당 파일을 CSV 형식으로 내보냅니다. \n",
    "        component_fname = os.path.join(INFER_DATA, 'input', f'{component}_{current_timestamp}.csv')\n",
    "        signals_df.to_csv(component_fname, index=None)\n",
    "    \n",
    "    start = start + datetime.timedelta(minutes=+frequency)\n",
    "    \n",
    "# 입력 위치의 전체 폴더를 S3에 업로드합니다. \n",
    "INFERENCE_INPUT = os.path.join(INFER_DATA, 'input')\n",
    "!aws s3 cp --recursive --quiet $INFERENCE_INPUT s3://$BUCKET/$PREFIX/input\n",
    "    \n",
    "# 이제 데이터를 준비했으므로 다음을 실행하여 스케줄러를 만듭니다.\n",
    "create_scheduler_response = scheduler.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스케줄러가 실행 중이며 추론 기록은 현재 비어 있습니다.\n",
    "\n",
    "![Scheduler created](../assets/schedule_created.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추론 결과 얻기\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추론 실행 결과 나열하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**스케줄러가 추론을 최초로 실행할 경우 5-15분 정도 걸립니다.** 대기가 끝나면 현재 추론 스케줄러에서 ListInferenceExecution API를 사용할 수 있습니다. 입력 파라미터로 스케줄러 명만 필요합니다.\n",
    "\n",
    "추론 실행 결과를 질의할 기간을 선택할 수 있습니다. 지정하지 않으면 추론 스케줄러에 대한 모든 실행 결과들이 나열됩니다. 시간 범위를 지정하려면 다음과 같이 합니다.\n",
    "\n",
    "```python\n",
    "START_TIME_FOR_INFERENCE_EXECUTIONS = datetime.datetime(2010,1,3,0,0,0)\n",
    "END_TIME_FOR_INFERENCE_EXECUTIONS = datetime.datetime(2010,1,5,0,0,0)\n",
    "```\n",
    "\n",
    "즉, `2010-01-03 00:00:00`부터 `2010-01-05 00:00:00`까지의 실행 결과들이 나열됩니다.\n",
    "\n",
    "특정 상태의 실행 결과를 질의하도록 선택할 수도 있습니다. 허용되는 상태는 `IN_PROGRESS`, `SUCCESS`와 `FAILED`입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAITING FOR THE FIRST INFERENCE EXECUTION\n",
      "WAITING FOR THE FIRST INFERENCE EXECUTION\n",
      "FIRST INFERENCE EXECUTED\n",
      "\n"
     ]
    }
   ],
   "source": [
    "START_TIME_FOR_INFERENCE_EXECUTIONS = None\n",
    "END_TIME_FOR_INFERENCE_EXECUTIONS = None\n",
    "EXECUTION_STATUS = None\n",
    "\n",
    "execution_summaries = []\n",
    "\n",
    "while len(execution_summaries) == 0:\n",
    "    execution_summaries = scheduler.list_inference_executions(\n",
    "        start_time=START_TIME_FOR_INFERENCE_EXECUTIONS,\n",
    "        end_time=END_TIME_FOR_INFERENCE_EXECUTIONS,\n",
    "        execution_status=EXECUTION_STATUS\n",
    "    )\n",
    "    if len(execution_summaries) == 0:\n",
    "        print('WAITING FOR THE FIRST INFERENCE EXECUTION')\n",
    "        time.sleep(60)\n",
    "        \n",
    "    else:\n",
    "        print('FIRST INFERENCE EXECUTED\\n')\n",
    "        break\n",
    "            \n",
    "# execution_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스케줄러를 5분마다 실행하도록 구성했습니다. 몇 분 후 콘솔에서 첫 번째 실행 결과가 입력된 기록을 살펴볼 수 있습니다. \n",
    "\n",
    "![Inference history](../assets/schedule_inference_history.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스케줄러가 시작될 때, 예를 들어 `datetime.datetime (2021, 1, 27, 9, 15)`일 때 입력 위치에서 **단일** CSV 파일을 찾습니다. 여기에는 타임스탬프가 포함된 파일 명이, 말하자면 다음과 같은 파일 명이 존재해야 합니다.\n",
    "\n",
    "* subsystem-01_2021012709**10**00.csv가 검색되고 수집됩니다.\n",
    "* subsystem-01_2021012709**15**00.csv는 수집되지 **않습니다** (다음 추론 실행 시 수집됨).\n",
    "\n",
    "`subsystem-01_20210127091000.csv` 파일을 연 다음 추론 실행의 DataStartTime과 DataEndTime 사이에 존재하는 시간 행을 찾습니다. 그러한 행을 찾지 못하면 내부 예외를 발생시킵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실제 예측 결과 얻기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추론에 성공하면 CSV 파일이 버킷의 출력 위치에 저장됩니다. 각 추론은 `results.csv` 단일 파일이 존재하는 새 폴더를 만듭니다. 해당 파일을 읽고 여기에 내용을 표시해 보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-04-03 06:00:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Predictions\n",
       "Timestamp                       \n",
       "2021-04-03 06:00:00            0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = scheduler.get_predictions()\n",
    "results_df.to_csv(os.path.join(INFER_DATA, 'output', 'results.csv'))\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추론 스케줄러 운영\n",
    "---\n",
    "### 추론 스케줄러 중단하기\n",
    "**근검 절약해야합니다**. 스케줄러 실행이 Amazon Lookout for Equipment 비용의 주된 원인입니다. 다음 API를 이용하여 현재 실행 중인 추론 스케줄러를 중지시키세요. 그렇게 하면 주기적인 추론 실행이 중지됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Polling Inference Scheduler Status =====\n",
      "\n",
      "Scheduler Status: STOPPING\n",
      "Scheduler Status: STOPPED\n",
      "\n",
      "===== End of Polling Inference Scheduler Status =====\n"
     ]
    }
   ],
   "source": [
    "scheduler.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추론 스케줄러 시작하기\n",
    "다음 API를 사용하여 `STOPPED` 추론 스케줄러를 재시작할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Polling Inference Scheduler Status =====\n",
      "\n",
      "Scheduler Status: PENDING\n",
      "Scheduler Status: RUNNING\n",
      "\n",
      "===== End of Polling Inference Scheduler Status =====\n"
     ]
    }
   ],
   "source": [
    "scheduler.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추론 스케줄러 삭제하기\n",
    "더 이상 사용하지 않는, **중지된** 스케줄러를 삭제할 수 있습니다. 모델 당 하나의 스케줄러만 가질 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Polling Inference Scheduler Status =====\n",
      "\n",
      "Scheduler Status: STOPPING\n",
      "Scheduler Status: STOPPED\n",
      "\n",
      "===== End of Polling Inference Scheduler Status =====\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'a639de53-6be0-4b43-a3ca-084c8532c214',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'a639de53-6be0-4b43-a3ca-084c8532c214',\n",
       "   'content-type': 'application/x-amz-json-1.0',\n",
       "   'content-length': '0',\n",
       "   'date': 'Sat, 03 Apr 2021 06:06:53 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.stop()\n",
    "scheduler.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결론\n",
    "---\n",
    "이 노트북에서는 노트북 시리즈 파트 3에서 만든 모델을 사용하여 스케줄러를 구성하고 몇 차례 추론을 실행한 다음 예측값을 얻었습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
